{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI, or Gen AI, refers to a class of artificial intelligence systems designed to create content, such as text, images, music, and more, by learning patterns from existing data. These models, like GPT-3 and DALL-E, utilize deep learning techniques to generate new and original outputs that can mimic human creativity. The applications of Gen AI are vast, ranging from enhancing creative processes in art and writing to automating tasks in various industries. As this technology continues to evolve, it raises important discussions about ethics, originality, and the future of human creativity, making it a fascinating area of exploration in the field of AI.\n"
     ]
    }
   ],
   "source": [
    "from g4f.client import Client\n",
    "client = Client()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a paragraph about Gen AI.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g4f.client import Client as OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "You are an expert the medical field.Given the symptoms {symptoms}, it is your job to \\\n",
    "create a paragraph of {number} 5 in which you will mention the disease and the potential treatments or medicines.\n",
    "Make sure to be precise even if you don't know say it because different medicine can kill people.\n",
    "Ensure to make {number} lines.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"number\",\"symptoms\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=[\"subject\",\"quiz\"],\n",
    "    template=TEMPLATE2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = quiz_generation_prompt.format(\n",
    "    number=5,\n",
    "    symptoms=[\"Abdominal pain and cramping\",\"Chronic diarrhea\",\"Fatigue\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completions(response_message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": response_message}]\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the symptoms of abdominal pain and cramping, chronic diarrhea, and fatigue, it is possible that the individual may be suffering from inflammatory bowel disease (IBD), such as Crohn's disease or ulcerative colitis. Treatment for IBD typically involves a combination of medication, dietary changes, and lifestyle modifications. Medications such as anti-inflammatory drugs, immunosuppressants, and biologic therapies may be prescribed to manage symptoms and reduce inflammation in the digestive tract. It is important for individuals with IBD to work closely with their healthcare provider to develop a personalized treatment plan that addresses their specific needs and concerns. In some cases, surgery may be necessary to remove damaged portions of the digestive tract. Therefore it is crucial for individuals experiencing these symptoms to seek medical attention promptly for an accurate diagnosis and appropriate treatment recommendations.\n"
     ]
    }
   ],
   "source": [
    "completions(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert in medical theorapy. Given a Multiple con {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g4f.client import Client\n",
    "message=\"\"\n",
    "client = Client()\n",
    "response = client.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['quiz', 'subject'], input_types={}, partial_variables={}, template='\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nif the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<g4f.Provider.ChatgptFree...t at 0x0000021D19D0A720>, input_type=ChatgptFree]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<g4f.Provider.ChatgptFree...t at 0x0000021D19D0A720>, input_type=ChatgptFree]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m review_chain\u001b[38;5;241m=\u001b[39mLLMChain(llm\u001b[38;5;241m=\u001b[39mllm,prompt\u001b[38;5;241m=\u001b[39mquiz_evaluation_prompt,output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:213\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     emit_warning()\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\load\\serializable.py:111\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<g4f.Provider.ChatgptFree...t at 0x0000021D19D0A720>, input_type=ChatgptFree]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<g4f.Provider.ChatgptFree...t at 0x0000021D19D0A720>, input_type=ChatgptFree]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "review_chain=LLMChain(llm=llm,prompt=quiz_evaluation_prompt,output_key=\"review\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='C:/Users/TOPINFORMATIQUE/mcq_generator/data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path,'r') as file:\n",
    "    data=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"artificial intelligence\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Artificial intelligence (AI) refers to the simulation of human intelligence in machines programmed to think, learn, and perform tasks typically requiring human intelligence. AI encompasses a range of technologies, from basic rule-based systems to advanced machine learning models that can analyze large datasets and make autonomous decisions. The ultimate goal of AI is to create systems capable of perceiving, reasoning, learning, and interacting with the world in ways that mimic or even surpass human abilities.\n",
      "You are an expert MCQ maker.Given the above text, it is your job to create a quiz of 5 multiple choice questions for artificial intelligence students in simple tone.\n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make shure to format your response like RESPONSE_JSON below and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m----> 2\u001b[0m     response\u001b[38;5;241m=\u001b[39mgenerate_evaluate_chain(\n\u001b[0;32m      3\u001b[0m         {\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: data,\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m: NUMBER,\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m:SUBJECT,\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtone\u001b[39m\u001b[38;5;124m\"\u001b[39m: TONE,\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_json\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(RESPONSE_JSON)\n\u001b[0;32m      9\u001b[0m         }\n\u001b[0;32m     10\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:179\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     emit_warning()\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    390\u001b[0m     inputs,\n\u001b[0;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    394\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\sequential.py:107\u001b[0m, in \u001b[0;36mSequentialChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chain \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains):\n\u001b[0;32m    106\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m _run_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[1;32m--> 107\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m chain(known_values, return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m    108\u001b[0m     known_values\u001b[38;5;241m.\u001b[39mupdate(outputs)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: known_values[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_variables}\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:179\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     emit_warning()\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    390\u001b[0m     inputs,\n\u001b[0;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    394\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    139\u001b[0m         prompts,\n\u001b[0;32m    140\u001b[0m         stop,\n\u001b[0;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:784\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    778\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    782\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    783\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:641\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    640\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    642\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    643\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    645\u001b[0m ]\n\u001b[0;32m    646\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:631\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    630\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 631\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    632\u001b[0m                 m,\n\u001b[0;32m    633\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    634\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    635\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    636\u001b[0m             )\n\u001b[0;32m    637\u001b[0m         )\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:850\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 850\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    851\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    852\u001b[0m         )\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:475\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m }\n\u001b[1;32m--> 475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    476\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    477\u001b[0m )\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:386\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    388\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:742\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    739\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    740\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    741\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    744\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    745\u001b[0m             {\n\u001b[0;32m    746\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    747\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    748\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    749\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    750\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    751\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    752\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    753\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    754\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    755\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    756\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    757\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    758\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    759\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    760\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    761\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    762\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    763\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    764\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    765\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    766\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    767\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    768\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    769\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    770\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    771\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    772\u001b[0m             },\n\u001b[0;32m    773\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    774\u001b[0m         ),\n\u001b[0;32m    775\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    776\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    777\u001b[0m         ),\n\u001b[0;32m    778\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    779\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    780\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    781\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    948\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    949\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    950\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    951\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    952\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    953\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1036\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1035\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1037\u001b[0m         input_options,\n\u001b[0;32m   1038\u001b[0m         cast_to,\n\u001b[0;32m   1039\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1040\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1041\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1042\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1043\u001b[0m     )\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1085\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1086\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1087\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1088\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1089\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1090\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1091\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1036\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1035\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1037\u001b[0m         input_options,\n\u001b[0;32m   1038\u001b[0m         cast_to,\n\u001b[0;32m   1039\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1040\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1041\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1042\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1043\u001b[0m     )\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1085\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1086\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1087\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1088\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1089\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1090\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1091\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\openai\\_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1050\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1054\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1055\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1060\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": data,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting g4f[all]\n",
      "  Using cached g4f-0.3.2.9-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (2.32.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (3.10.8)\n",
      "Requirement already satisfied: brotli in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (1.0.9)\n",
      "Collecting pycryptodome (from g4f[all])\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting curl-cffi>=0.6.2 (from g4f[all])\n",
      "  Using cached curl_cffi-0.7.2-cp38-abi3-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (2024.8.30)\n",
      "Collecting browser-cookie3 (from g4f[all])\n",
      "  Using cached browser_cookie3-0.19.1-py3-none-any.whl.metadata (632 bytes)\n",
      "Collecting PyExecJS (from g4f[all])\n",
      "  Using cached PyExecJS-1.5.1.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting duckduckgo-search>=5.0 (from g4f[all])\n",
      "  Downloading duckduckgo_search-6.2.13-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (4.12.3)\n",
      "Collecting pywebview (from g4f[all])\n",
      "  Downloading pywebview-5.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (3.10.0)\n",
      "Collecting plyer (from g4f[all])\n",
      "  Downloading plyer-2.1.0-py2.py3-none-any.whl.metadata (61 kB)\n",
      "Collecting cryptography (from g4f[all])\n",
      "  Downloading cryptography-43.0.1-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting aiohttp-socks (from g4f[all])\n",
      "  Downloading aiohttp_socks-0.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (10.4.0)\n",
      "Collecting cairosvg (from g4f[all])\n",
      "  Downloading CairoSVG-2.7.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting werkzeug (from g4f[all])\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting flask (from g4f[all])\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting loguru (from g4f[all])\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting fastapi (from g4f[all])\n",
      "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn (from g4f[all])\n",
      "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from g4f[all]) (1.6.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from curl-cffi>=0.6.2->g4f[all]) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from curl-cffi>=0.6.2->g4f[all]) (4.11.0)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from duckduckgo-search>=5.0->g4f[all]) (8.1.7)\n",
      "Collecting primp>=0.6.3 (from duckduckgo-search>=5.0->g4f[all])\n",
      "  Downloading primp-0.6.3-cp38-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from aiohttp->g4f[all]) (1.13.1)\n",
      "Collecting python-socks<3.0.0,>=2.4.3 (from python-socks[asyncio]<3.0.0,>=2.4.3->aiohttp-socks->g4f[all])\n",
      "  Downloading python_socks-2.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from beautifulsoup4->g4f[all]) (2.5)\n",
      "Collecting lz4 (from browser-cookie3->g4f[all])\n",
      "  Downloading lz4-4.3.3-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting pycryptodomex (from browser-cookie3->g4f[all])\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting cairocffi (from cairosvg->g4f[all])\n",
      "  Downloading cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cssselect2 (from cairosvg->g4f[all])\n",
      "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from cairosvg->g4f[all]) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from cairosvg->g4f[all]) (1.2.1)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->g4f[all])\n",
      "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from fastapi->g4f[all]) (2.9.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from flask->g4f[all]) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask->g4f[all])\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from flask->g4f[all]) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from werkzeug->g4f[all]) (2.1.3)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from loguru->g4f[all]) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru->g4f[all])\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from PyExecJS->g4f[all]) (1.16.0)\n",
      "Collecting proxy-tools (from pywebview->g4f[all])\n",
      "  Downloading proxy_tools-0.1.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bottle (from pywebview->g4f[all])\n",
      "  Downloading bottle-0.13.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pythonnet (from pywebview->g4f[all])\n",
      "  Downloading pythonnet-3.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from requests->g4f[all]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from requests->g4f[all]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from requests->g4f[all]) (2.2.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from uvicorn->g4f[all]) (0.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->g4f[all]) (2.21)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->g4f[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->g4f[all]) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from starlette<0.39.0,>=0.37.2->fastapi->g4f[all]) (4.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from cssselect2->cairosvg->g4f[all]) (0.5.1)\n",
      "Collecting clr-loader<0.3.0,>=0.2.6 (from pythonnet->pywebview->g4f[all])\n",
      "  Downloading clr_loader-0.2.6-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\topinformatique\\anaconda3\\envs\\end2end\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi->g4f[all]) (1.3.0)\n",
      "Downloading curl_cffi-0.7.2-cp38-abi3-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 762.0 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 762.0 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.8/4.0 MB 798.0 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.8/4.0 MB 798.0 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 762.0 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/4.0 MB 745.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/4.0 MB 745.3 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.6/4.0 MB 755.5 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/4.0 MB 756.5 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.8/4.0 MB 756.5 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.1/4.0 MB 762.4 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.1/4.0 MB 762.4 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 771.3 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.6/4.0 MB 758.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.6/4.0 MB 758.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 752.2 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 752.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.1/4.0 MB 756.2 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 759.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 759.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.7/4.0 MB 759.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/4.0 MB 760.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 739.2 kB/s eta 0:00:00\n",
      "Downloading duckduckgo_search-6.2.13-py3-none-any.whl (27 kB)\n",
      "Downloading aiohttp_socks-0.9.0-py3-none-any.whl (9.7 kB)\n",
      "Downloading browser_cookie3-0.19.1-py3-none-any.whl (14 kB)\n",
      "Downloading CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n",
      "Downloading cryptography-43.0.1-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.1 MB 799.2 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.8/3.1 MB 799.2 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.8/3.1 MB 799.2 kB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.0/3.1 MB 786.4 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.3/3.1 MB 771.0 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.3/3.1 MB 771.0 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.6/3.1 MB 762.5 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.6/3.1 MB 762.5 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 768.4 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.1/3.1 MB 767.5 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.1/3.1 MB 767.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.4/3.1 MB 771.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.1 MB 766.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.1 MB 766.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.9/3.1 MB 766.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.9/3.1 MB 766.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 736.5 kB/s eta 0:00:00\n",
      "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading g4f-0.3.2.9-py3-none-any.whl (617 kB)\n",
      "   ---------------------------------------- 0.0/617.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/617.8 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/617.8 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/617.8 kB ? eta -:--:--\n",
      "   -------------------------------------- 617.8/617.8 kB 758.3 kB/s eta 0:00:00\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Downloading plyer-2.1.0-py2.py3-none-any.whl (142 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 764.3 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 799.2 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 799.2 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 786.4 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 789.6 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 789.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 755.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 755.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 757.9 kB/s eta 0:00:00\n",
      "Downloading pywebview-5.2-py3-none-any.whl (446 kB)\n",
      "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading primp-0.6.3-cp38-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 509.0 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 781.4 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 781.4 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.8 MB 786.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 789.6 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.8 MB 789.6 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 784.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.8/2.8 MB 780.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.8/2.8 MB 780.6 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.1/2.8 MB 758.0 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.8 MB 758.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.8 MB 762.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.8 MB 766.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.8 MB 766.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 700.6 kB/s eta 0:00:00\n",
      "Downloading python_socks-2.5.2-py3-none-any.whl (52 kB)\n",
      "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
      "Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Downloading bottle-0.13.1-py2.py3-none-any.whl (103 kB)\n",
      "Downloading cairocffi-1.7.1-py3-none-any.whl (75 kB)\n",
      "Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
      "Downloading lz4-4.3.3-cp312-cp312-win_amd64.whl (99 kB)\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 799.2 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 799.2 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 780.2 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 780.2 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 740.5 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 737.4 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 737.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 749.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 749.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 747.9 kB/s eta 0:00:00\n",
      "Downloading pythonnet-3.0.4-py3-none-any.whl (295 kB)\n",
      "Downloading clr_loader-0.2.6-py3-none-any.whl (51 kB)\n",
      "Building wheels for collected packages: PyExecJS, proxy-tools\n",
      "  Building wheel for PyExecJS (setup.py): started\n",
      "  Building wheel for PyExecJS (setup.py): finished with status 'done'\n",
      "  Created wheel for PyExecJS: filename=PyExecJS-1.5.1-py3-none-any.whl size=14609 sha256=344f1835a15382f454470c5a889a6261c4214baec9cf781e55e36ff219204dbf\n",
      "  Stored in directory: c:\\users\\topinformatique\\appdata\\local\\pip\\cache\\wheels\\95\\1c\\16\\774a935204aacf741cea3deae76c535050d19727c72613d80f\n",
      "  Building wheel for proxy-tools (setup.py): started\n",
      "  Building wheel for proxy-tools (setup.py): finished with status 'done'\n",
      "  Created wheel for proxy-tools: filename=proxy_tools-0.1.0-py3-none-any.whl size=2910 sha256=ce39d9798f903def558e73285efcd9add4c5dfb7a184cf69df6aa9cd5ec43ad3\n",
      "  Stored in directory: c:\\users\\topinformatique\\appdata\\local\\pip\\cache\\wheels\\07\\37\\12\\f3390260c831aa68c3835d6ec2e10d8da094b5fc0ac32feb14\n",
      "Successfully built PyExecJS proxy-tools\n",
      "Installing collected packages: python-socks, proxy-tools, plyer, bottle, win32-setctime, werkzeug, PyExecJS, pycryptodomex, pycryptodome, primp, lz4, itsdangerous, uvicorn, starlette, loguru, flask, duckduckgo-search, curl-cffi, cssselect2, cryptography, clr-loader, cairocffi, browser-cookie3, pythonnet, g4f, fastapi, cairosvg, aiohttp-socks, pywebview\n",
      "Successfully installed PyExecJS-1.5.1 aiohttp-socks-0.9.0 bottle-0.13.1 browser-cookie3-0.19.1 cairocffi-1.7.1 cairosvg-2.7.1 clr-loader-0.2.6 cryptography-43.0.1 cssselect2-0.7.0 curl-cffi-0.7.2 duckduckgo-search-6.2.13 fastapi-0.115.0 flask-3.0.3 g4f-0.3.2.9 itsdangerous-2.2.0 loguru-0.7.2 lz4-4.3.3 plyer-2.1.0 primp-0.6.3 proxy-tools-0.1.0 pycryptodome-3.21.0 pycryptodomex-3.21.0 python-socks-2.5.2 pythonnet-3.0.4 pywebview-5.2 starlette-0.38.6 uvicorn-0.31.0 werkzeug-3.0.4 win32-setctime-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U g4f[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error in synchronous image generation: This event loop is already running\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\g4f\\client\\client.py:209\u001b[0m, in \u001b[0;36mImages.generate\u001b[1;34m(self, prompt, model, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 209\u001b[0m     result \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_generate(prompt, model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    210\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynchronous image generation completed. Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\asyncio\\base_events.py:663\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_running()\n\u001b[0;32m    665\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\asyncio\\base_events.py:622\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mg4f\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[1;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      5\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m   prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma white siamese cat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m image_url \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\site-packages\\g4f\\client\\client.py:217\u001b[0m, in \u001b[0;36mImages.generate\u001b[1;34m(self, prompt, model, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 217\u001b[0m         loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\TOPINFORMATIQUE\\anaconda3\\envs\\end2end\\Lib\\asyncio\\proactor_events.py:687\u001b[0m, in \u001b[0;36mBaseProactorEventLoop.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 687\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot close a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_closed():\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    }
   ],
   "source": [
    "from g4f.client import Client\n",
    "\n",
    "client = Client()\n",
    "response = client.images.generate(\n",
    "  model=\"gemini\",\n",
    "  prompt=\"a white siamese cat\"\n",
    ")\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end2end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
